{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вот еще один вопрос\n",
    "https://github.com/evfro/polara/blob/master/polara/recommender/models.py#L848\n",
    "Ты вычислиаешь predition как \n",
    " `scores = (test_matrix.dot(v)).dot(v.T)`\n",
    "Где `v` до этого \n",
    " `user_factors, sigma, item_factors = svds(svd_matrix, **svd_params)`\n",
    " `item_factors = item_factors.T`\n",
    " Для general Matrix-Factorisation (я про ALS, funkSVD case где за модель берется любое расложение R = U * V ) \n",
    " для каждого юзера нам надо решить линейное уравнение вида:\n",
    " `Ux * v = Ru` , где `Ru` строчка с интеракциями нового customera. ( я прав кстати в этом утверждении или нет ? \n",
    "  ибо я сталкиваюсь с тотальним игнором этого биснес кейса (то что ты у себя в PHD называешь onlne-recomendation ) в очень большом количестве алгоритмов что DEEP что и LINEAR,\n",
    " но в тоже время это просто стандартний биснес сценарий - есть эмбединги итемов есть свойства пользователя на уровне \n",
    " фич онлайн и векторов интеракций, а не эмбединг полсователя на прямую )\n",
    " \n",
    " с СВД все проще и мы можем сказать что `Ux`  ортогонален вектору `Ru  * v` , поскольку мы потом используем \n",
    " сцалярное произведение как метрику сходства , то нам этого достаточно  - ето утверждение не понимаю - интуитиця \n",
    " тут как бы понятна  но я не смог доказать это строго. Более того мне кажется надо считать `Ux` не как  `Ru * v`  а как `Ru * ( s * v )`.\n",
    " \n",
    " Внизу я предлагаю простой пример 3 х 3 где один пользователь имеет для просты одну интеракцию с одним итемом что по интуции должно давать этому пользователю вектор этого итема. \n",
    " \n",
    " Можешь указать мне где я не прав ? Более того я провел эксперимент и на моих данных твоя формула \n",
    "\n",
    " `scores = (test_matrix.dot(v)).dot(v.T)`\n",
    "\n",
    "работает лучше чем \n",
    "\n",
    " `scores = (test_matrix.dot(dot(s,v))).dot(v.T)`\n",
    "\n",
    "Но если модель по восстановленому юзеру и по юзеру внутри системы с абсолютно иднтичным набором данных дает разные предикшины векторов то с этим что-то не так.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "U=[[-0.3856283   0.60700632  0.69486268]\n",
      " [-0.92153412 -0.21629532 -0.32247668]\n",
      " [-0.04544984 -0.7646958   0.64278663]]\n",
      "s=[9.51777851 1.1565543  0.27253334]\n",
      "v=[[-0.43258147 -0.56514524 -0.70248426]\n",
      " [-0.88441222  0.11459561  0.45241892]\n",
      " [ 0.17518078 -0.8169937   0.54939329]]\n",
      "WARM USER s odnoj interakciej = [-0.04544984 -0.7646958   0.64278663] NORM=1.0\n",
      "COLD USER odnoj interakciej (reconstrovanij)= [-0.43258147 -0.88441222  0.17518078] NORM=0.9999999999999998\n",
      "DOT TEST reconstructedUser x testUser = 0.8085709269795148\n",
      "COLD USER s odnoj interakciej (reconstrovanij)= [-0.43258147 -0.88441222  0.17518078] NORM=0.9999999999999998\n",
      "DOT TEST reconstructedUser x testUser = 0.8085709269795148\n",
      "COLD USER s odnoj interakciej (reconstrovanij)= [-4.1172146  -1.02287075  0.0477426 ] NORM=18.000000000000018\n",
      "DOT TEST reconstructedUser x testUser = 1.0000000000000002\n",
      "COLD USER s odnoj interakciej (reconstrovanij)= [-4.1172146  -1.02287075  0.0477426 ] NORM=18.000000000000018\n",
      "DOT TEST reconstructedUser x testUser = 1.0000000000000002\n"
     ]
    }
   ],
   "source": [
    "# Vot basovij primer \n",
    "\n",
    "import numpy as np\n",
    "from scipy import linalg\n",
    "\n",
    "R = np.array([\n",
    "     [1,2,3],\n",
    "     [4,5,6],\n",
    "     [1,0,0]]\n",
    ")\n",
    "\n",
    "U, s, v = linalg.svd(R)\n",
    "\n",
    "print(f\"U={U}\")\n",
    "print(f\"s={s}\")\n",
    "print(f\"v={v}\")\n",
    "\n",
    "testUser = U[-1,:]\n",
    "print(f\"WARM USER s odnoj interakciej = {testUser} NORM={np.dot(testUser,testUser)}\")\n",
    "\n",
    "reconstructedUser = v[:,0]\n",
    "print(f\"COLD USER odnoj interakciej (reconstrovanij)= {reconstructedUser} NORM={np.dot(reconstructedUser,reconstructedUser)}\")\n",
    "print(f\"DOT TEST reconstructedUser x testUser = {np.dot(testUser,reconstructedUser)}\")\n",
    "\n",
    "# The same but based on code. \n",
    "reconstructedUser = np.dot( R[-1:].reshape((1,3)) , v.T )[0]\n",
    "print(f\"COLD USER s odnoj interakciej (reconstrovanij)= {reconstructedUser} NORM={np.dot(reconstructedUser,reconstructedUser)}\")\n",
    "print(f\"DOT TEST reconstructedUser x testUser = {np.dot(testUser,reconstructedUser)}\")\n",
    "\n",
    "\n",
    "# Use Items matrix as s * v \n",
    "sigma = np.zeros((m, n))\n",
    "for i in range(min(m, n)):\n",
    "    sigma[i, i] = s[i]\n",
    "svh = np.dot(sigma,Vh)\n",
    "\n",
    "reconstructedUser = svh[:,0]\n",
    "print(f\"COLD USER s odnoj interakciej (reconstrovanij)= {reconstructedUser} NORM={np.dot(reconstructedUser,reconstructedUser)}\")\n",
    "print(f\"DOT TEST reconstructedUser x testUser = {np.dot(testUser,reconstructedUser)}\")\n",
    "\n",
    "# The same but based on code. \n",
    "reconstructedUser = np.dot( R[-1:].reshape((1,3)) , svh.T )[0]\n",
    "print(f\"COLD USER s odnoj interakciej (reconstrovanij)= {reconstructedUser} NORM={np.dot(reconstructedUser,reconstructedUser)}\")\n",
    "print(f\"DOT TEST reconstructedUser x testUser = {np.dot(testUser,reconstructedUser)}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
